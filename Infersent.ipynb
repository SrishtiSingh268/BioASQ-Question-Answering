{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'nli/infersent/'\n",
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli/infersent\n"
     ]
    }
   ],
   "source": [
    "cd nli/infersent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "GLOVE_PATH = '/Volumes/Nitish-Passport/bioasq_files/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved_models/infersent.allnli.pickle'\n",
    "model = torch.load(model_path, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_glove_path(GLOVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'This is a sample sentence.',\n",
    "    'The cat likes to walk.',\n",
    "    'The cat likes to talk.',\n",
    "    'The dog likes to talk.',\n",
    "    'This is a completely unrelated sentence.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17(/17) words with glove vectors\n",
      "Vocab size : 17\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 31/36 (86.11 %)\n",
      "Speed : 7.6 sentences/s (cpu mode, bsize=2)\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(sentences, bsize=2, tokenize=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4096)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "def sim(sent1, sent2):\n",
    "    em = model.encode([sent1, sent2], tokenize=False, verbose=True)\n",
    "    return cosine(em[0], em[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'sentence',\n",
       " 'This',\n",
       " 'is',\n",
       " 'walk',\n",
       " 'dog',\n",
       " '.',\n",
       " 'sample',\n",
       " 'to',\n",
       " 'completely',\n",
       " 'unrelated',\n",
       " 'likes',\n",
       " 'The',\n",
       " 'cat',\n",
       " '</s>',\n",
       " 'talk',\n",
       " '<s>']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_word_dict(sentences).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "run data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "GLOVE_PATH = '/Volumes/Nitish-Passport/bioasq_files/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = [\n",
    "    'I do not want to go home.',\n",
    "    'He likes butter.',\n",
    "    'He never speaks loud.',\n",
    "    'The weather is good',\n",
    "    'What is the matter?',\n",
    "    'He never speaks loud.',\n",
    "    'He made two mistakes',\n",
    "]\n",
    "s2 = [\n",
    "    'I wish to go home.',\n",
    "    'He hates butter.',\n",
    "    'He never speaks soft.',\n",
    "    'The weather is bad',\n",
    "    'What is the matter with you?',\n",
    "    'He always speaks soft.',\n",
    "    'He made mistakes twice.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36(/36) words with glove vectors\n"
     ]
    }
   ],
   "source": [
    "word_dict = get_word_dict(s1 + s2)\n",
    "word_vec = get_glove(word_dict, GLOVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 0, 2, 0, 2, 0]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli_net = torch.load('saved_models/nlimodels/model.pickle', map_location='cpu')\n",
    "nli_net.eval()\n",
    "outputs = []\n",
    "for i in range(len(s1)):\n",
    "    ss1 = [['<s>'] + [word for word in word_tokenize(sent) if word in word_vec] +  ['</s>'] for sent in [s1[i]]]\n",
    "    ss2 = [['<s>'] + [word for word in word_tokenize(sent) if word in word_vec] +  ['</s>'] for sent in [s2[i]]]\n",
    "    # ss1 = sorted(ss1, key = lambda x: len(x), reverse=True)\n",
    "    # ss2 = sorted(ss2, key = lambda x: len(x), reverse=True)\n",
    "    s1_batch, s1_len = get_batch(ss1, word_vec)\n",
    "    s2_batch, s2_len = get_batch(ss2, word_vec)\n",
    "    s1_batch, s2_batch = Variable(s1_batch), Variable(s2_batch)\n",
    "    output = nli_net((s1_batch, s1_len), (s2_batch, s2_len))\n",
    "    outputs.append(output.data.max(1)[1].numpy()[0])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['I do not want to go home.',\n",
       "  'He likes butter.',\n",
       "  'He never speaks loud.',\n",
       "  'The weather is good',\n",
       "  'What is the matter?',\n",
       "  'He never speaks loud.',\n",
       "  'He made two mistakes'],\n",
       " ['I wish to go home.',\n",
       "  'He hates butter.',\n",
       "  'He never speaks soft.',\n",
       "  'The weather is bad',\n",
       "  'What is the matter with you?',\n",
       "  'He always speaks soft.',\n",
       "  'He made mistakes twice.'])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1, s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prostrcustus transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli/infersent/data\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/nli/infersent/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.load('matmul_glove_med.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, V = np.linalg.svd(mat, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 200), (200,), (200, 200))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape, s.shape, V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = U.dot(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('prostrcustus_transformation_matrix.npy', tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataLoader import DataLoader\n",
    "\n",
    "input_path = 'input/BioASQ-trainingDataset6b.json'\n",
    "# input_path = 'input/BioASQ-task6bPhaseB-testset3.json'\n",
    "data = DataLoader(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_vectors_file = '/Volumes/Nitish-Passport/bioasq_files/wikipedia-pubmed-and-PMC-w2v.bin'\n",
    "\n",
    "input_glove_file = '/Volumes/Nitish-Passport/bioasq_files/glove.840B.300d.txt'\n",
    "new_glove_file = '/Volumes/Nitish-Passport/bioasq_files/%s_glove.840B.300d.txt' % data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/nli/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run hypotheses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: /Users/nitish/.local/share/bllipparser/GENIA+PubMed\n",
      "Model directory already exists, not reinstalling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# RerankingParser._parser_model_loaded = False\n",
    "# rrp = RerankingParser.from_unified_model_dir('/Users/nitish/.local/share/bllipparser/GENIA+PubMed')\n",
    "# # fetch_and_load('GENIA+PubMed', verbose=True)\n",
    "# yesno = data.get_questions_of_type('yesno')\n",
    "# for q in tqdm(yesno):\n",
    "#     q.assertion_pos = q2s(q.question, rrp)\n",
    "set_assertions_for_yesno_questions(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesno = data.get_questions_of_type('yesno')\n",
    "all_sentences = []\n",
    "for q in yesno:\n",
    "    all_sentences.append(q.assertion_pos)\n",
    "    all_sentences += q.snippet_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli/infersent\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/nli/infersent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = get_word_dict(all_sentences)\n",
    "tokens = word_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run create_glove_embeddings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubtator_vectors = word2vec.load(pubmed_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "\n",
    "with open('/Users/nitish/acads/11797/bioasq/nli/infersent/data/uncommon_vocab.pkl', 'rb') as fp:\n",
    "    uncommon_vocab = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = np.load('prostrcustus_transformation_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli/infersent\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 5000 words\n",
      "Finished 10000 words\n",
      "Finished 15000 words\n",
      "Finished 20000 words\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "with open(new_glove_file, 'w') as fp:\n",
    "    for word in tokens:\n",
    "        k += 1\n",
    "        if k % 5000 == 0:\n",
    "            print('Finished %d words' % k)\n",
    "        if word in uncommon_vocab and word in pubtator_vectors:\n",
    "            vec = tm.dot(pubtator_vectors[word][:, np.newaxis])[:, 0]\n",
    "            line = ' '.join([word] + [str(i) for i in vec])\n",
    "            fp.write('%s\\n' % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec = tm.dot(pubtator_vectors['localizes'][:, np.newaxis])[:, 0].shape\n",
    "# vec.lot_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run infersent on yesno questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run dataLoader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path = 'input/BioASQ-trainingDataset5b.json'\n",
    "# input_path = 'input/phaseB_5b_05.json'\n",
    "# input_path = 'input/BioASQ-trainingDataset6b.json'\n",
    "# input_path = 'input/BioASQ-task6bPhaseB-testset3.json'\n",
    "# input_path = 'input/BioASQ-task6bPhaseB-testset4.json'\n",
    "input_path = 'input/BioASQ-task6bPhaseB-testset5.json'\n",
    "data = DataLoader(input_path)\n",
    "\n",
    "input_glove_file = '/Volumes/Nitish-Passport/bioasq_files/glove.840B.300d.txt'\n",
    "new_glove_file = '/Volumes/Nitish-Passport/bioasq_files/%s_glove.840B.300d.txt' % data.name\n",
    "new_glove_file = '/Volumes/Nitish-Passport/bioasq_files/BioASQ-trainingDataset5b_glove.840B.300d.txt'\n",
    "new_glove_file = '/Volumes/Nitish-Passport/bioasq_files/BioASQ-trainingDataset6b_glove.840B.300d.txt'\n",
    "yesno_ans_file = 'output/yesno_%s.json' % data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/nli/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run hypotheses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: /Users/nitish/.local/share/bllipparser/GENIA+PubMed\n",
      "Model directory already exists, not reinstalling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  7.08it/s]\n"
     ]
    }
   ],
   "source": [
    "set_assertions_for_yesno_questions(data)\n",
    "\n",
    "yesno = data.get_questions_of_type('yesno')\n",
    "all_sentences = []\n",
    "for q in yesno:\n",
    "    all_sentences.append(q.assertion_pos)\n",
    "    all_sentences += q.snippet_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli/infersent\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/nli/infersent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 967(/1035) words with glove vectors\n"
     ]
    }
   ],
   "source": [
    "word_dict = get_word_dict(all_sentences)\n",
    "word_vec = get_glove(word_dict, input_glove_file, new_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yesno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitish/miniconda2/envs/bioasq/lib/python2.7/site-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/nitish/miniconda2/envs/bioasq/lib/python2.7/site-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/nitish/miniconda2/envs/bioasq/lib/python2.7/site-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4 None\n",
      "2 3 None\n",
      "0 2 None\n",
      "2 0 None\n",
      "0 1 None\n"
     ]
    }
   ],
   "source": [
    "nli_net = torch.load('saved_models/nlimodels/model.pickle', map_location='cpu')\n",
    "nli_net.eval()\n",
    "\n",
    "for q in yesno:\n",
    "    outputs = []\n",
    "    sentences = [i['text'] for i in q.ranked_sentences()[:20]]\n",
    "    s1, s2 = sentences, [q.assertion_pos] * len(sentences)\n",
    "#     s2, s1 = sentences, [q.assertion_pos] * len(sentences)\n",
    "#     if q.exact_answer_ref == 'yes':\n",
    "#         continue\n",
    "    total = 0\n",
    "    for i in range(len(s1)):\n",
    "        ss1 = [['<s>'] + [word for word in word_tokenize(sent) if word in word_vec] +  ['</s>'] for sent in [s1[i]]]\n",
    "        ss2 = [['<s>'] + [word for word in word_tokenize(sent) if word in word_vec] +  ['</s>'] for sent in [s2[i]]]\n",
    "        # ss1 = sorted(ss1, key = lambda x: len(x), reverse=True)\n",
    "        # ss2 = sorted(ss2, key = lambda x: len(x), reverse=True)\n",
    "        s1_batch, s1_len = get_batch(ss1, word_vec)\n",
    "        s2_batch, s2_len = get_batch(ss2, word_vec)\n",
    "        s1_batch, s2_batch = Variable(s1_batch), Variable(s2_batch)\n",
    "        output = nli_net((s1_batch, s1_len), (s2_batch, s2_len))\n",
    "        total += output\n",
    "        outputs.append(output.data.max(1)[1].numpy()[0])\n",
    "    print (np.array(outputs) == 0).sum(), (np.array(outputs) == 2).sum(), q.exact_answer_ref #, total.data.max(1)[1].numpy()[0] if total != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.5178 -0.6057 -0.9143\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitish/miniconda2/envs/bioasq/lib/python2.7/site-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/nitish/miniconda2/envs/bioasq/lib/python2.7/site-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/nitish/miniconda2/envs/bioasq/lib/python2.7/site-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "  5%|▌         | 1/20 [00:10<03:16, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:12<01:48,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:22<02:10,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:26<01:44,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [00:27<01:23,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [00:29<01:09,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [00:31<00:58,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [00:54<01:22,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [01:01<01:14,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [01:14<01:14,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [01:18<01:04,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [01:21<00:54,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [01:32<00:49,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [01:40<00:43,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [01:43<00:34,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [01:44<00:26,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [01:44<00:18,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [01:49<00:12,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [01:52<00:05,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 20/20 [01:57<00:00,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nli_net = torch.load('saved_models/nlimodels/model.pickle', map_location='cpu')\n",
    "nli_net.eval()\n",
    "\n",
    "def get_answer(n_entail, n_contradict):\n",
    "    if n_entail > n_contradict:\n",
    "        return 'yes'\n",
    "    elif n_contradict > n_entail:\n",
    "        return 'no'\n",
    "    else:\n",
    "        if n_entail == 0:\n",
    "            return 'no'\n",
    "        else:\n",
    "            return 'yes'\n",
    "\n",
    "entailments = []\n",
    "answers = []\n",
    "for q in tqdm(yesno):\n",
    "    outputs = []\n",
    "    sentences = [i['text'] for i in q.ranked_sentences()]\n",
    "    s1, s2 = sentences, [q.assertion_pos] * len(sentences)\n",
    "    total = 0\n",
    "    for i in range(len(s1)):\n",
    "        ss1 = [['<s>'] + [word for word in word_tokenize(sent) if word in word_vec] +  ['</s>'] for sent in [s1[i]]]\n",
    "        ss2 = [['<s>'] + [word for word in word_tokenize(sent) if word in word_vec] +  ['</s>'] for sent in [s2[i]]]\n",
    "        s1_batch, s1_len = get_batch(ss1, word_vec)\n",
    "        s2_batch, s2_len = get_batch(ss2, word_vec)\n",
    "        s1_batch, s2_batch = Variable(s1_batch), Variable(s2_batch)\n",
    "        output = nli_net((s1_batch, s1_len), (s2_batch, s2_len))\n",
    "        total += output\n",
    "        outputs.append(output.data.max(1)[1].numpy()[0])\n",
    "    n_entail = (np.array(outputs) == 0).sum()\n",
    "    n_contradict = (np.array(outputs) == 2).sum()\n",
    "    total_res = total.data.max(1)[1].numpy()[0] if isinstance(total, Variable) else 0\n",
    "    q.exact_answer = get_answer(n_entail, n_contradict)\n",
    "    answers.append((n_entail, n_contradict, q.exact_answer_ref, q.exact_answer))\n",
    "    print(q.exact_answer, q.exact_answer_ref)\n",
    "#     entailments.append((n_entail, n_contradict, total_res, q.exact_answer))\n",
    "\n",
    "# data.eval_yesno()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy = 0.568273 (283 / 498)\n",
      "YES Accuracy = 0.565611 (250 / 442)\n",
      "No Accuracy = 0.589286 (33 / 56)\n"
     ]
    }
   ],
   "source": [
    "def get_answer(n_entail, n_contradict):\n",
    "    if n_entail > n_contradict:\n",
    "        return 'yes'\n",
    "    elif n_contradict > n_entail:\n",
    "        return 'no'\n",
    "    else:\n",
    "        if n_entail == 0:\n",
    "            return 'no'\n",
    "        else:\n",
    "            return 'yes'\n",
    "\n",
    "def eval_yesno(questions):\n",
    "    yes_correct = 0.0\n",
    "    no_correct = 0.0\n",
    "    total_yes = 0.0\n",
    "    total_no = 0.0\n",
    "\n",
    "    for q in questions:\n",
    "        if not q.exact_answer_ref or not q.exact_answer:\n",
    "            continue\n",
    "        q.exact_answer_ref = q.exact_answer_ref.lower()\n",
    "        if q.exact_answer_ref == 'yes':\n",
    "            total_yes += 1\n",
    "            yes_correct += (q.exact_answer_ref == q.exact_answer)\n",
    "        if q.exact_answer_ref == 'no':\n",
    "            total_no += 1\n",
    "            no_correct += (q.exact_answer_ref == q.exact_answer)\n",
    "\n",
    "    total_correct = yes_correct + no_correct\n",
    "    total_q = total_yes + total_no\n",
    "    total_acc = total_correct / total_q if total_q > 0 else 0\n",
    "    yes_acc = yes_correct / total_yes if total_yes > 0 else 0\n",
    "    no_acc = no_correct / total_no if total_no > 0 else 0\n",
    "    print('Total Accuracy = %2f (%d / %d)' % (total_acc, total_correct, total_q))\n",
    "    print('YES Accuracy = %2f (%d / %d)' % (yes_acc, yes_correct, total_yes))\n",
    "    print('No Accuracy = %2f (%d / %d)' % (no_acc, no_correct, total_no))\n",
    "\n",
    "for itr, q in enumerate(yesno):\n",
    "    q.exact_answer = get_answer(answers[itr][0], answers[itr][1])\n",
    "\n",
    "eval_yesno(yesno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save_yesno_answers(yesno_ans_file)\n",
    "# data.load_answers_from_file(yesno_ans_file, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the protein Papilin secreted? yes yes\n",
      "Are long non coding RNAs spliced? yes yes\n",
      "Is RANKL secreted from the cells? yes yes\n",
      "Does metformin interfere thyroxine absorption? no no\n",
      "Has Denosumab (Prolia) been approved by FDA? no yes\n",
      "Is the monoclonal antibody Trastuzumab (Herceptin) of potential use in the treatment of prostate cancer? no yes\n",
      "Are transcription and splicing connected? yes yes\n",
      "Is Alu hypomethylation associated with breast cancer? yes yes\n",
      "Proteomic analyses need prior knowledge of the organism complete genome. Is the complete genome of the bacteria of the genus Arthrobacter available? no yes\n",
      "Do mutations of AKT1 occur in meningiomas? no yes\n",
      "Does physical activity influence gut hormones? yes yes\n",
      "Is irritable bowel syndrome more common in women with endometriosis? yes yes\n",
      "Does BNP increase after intensive exercise in athletes? yes yes\n",
      "Are there web based self management strategies for chronic pain ? yes yes\n",
      "Is Weaver syndrome similar to Sotos? yes yes\n",
      "Are ultraconserved elements often transcribed? yes yes\n",
      "Is peripheral neuroepithelioma related to Ewing sarcoma? yes yes\n",
      "Is c-met involved in the activation of the Akt pathway? yes yes\n",
      "Is pregnancy an additional risk during during H1N1 infection? yes yes\n",
      "Is there a crystal structure of Greek Goat Encephalitis? no no\n",
      "Are long non coding RNAs as conserved in sequence as protein coding genes? no no\n",
      "Is TENS machine effective in pain? yes yes\n",
      "Is there any algorithm for enhancer identification from chromatin state? no yes\n",
      "Are transcribed ultraconserved regions involved in cancer? yes yes\n",
      "Do patients with Pendred syndrome present congenital deafness? yes yes\n",
      "Is CD56 useful in Ewing sarcoma prognosis? yes yes\n",
      "Are there any urine biomarkers for chronic kidney disease? no yes\n",
      "Is valproic acid effective for glioblastoma treatment? no yes\n",
      "Can Levoxyl (levothyroxine sodium) cause insomnia? no yes\n",
      "Is fatigue prevalent in patients receiving treatment for glioblastoma? yes yes\n",
      "Have Quantitative Trait Loci affecting splicing (splicing QTLs) been linked to disease? no yes\n",
      "Does the CTCF protein co-localize with cohesin? no yes\n",
      "Are stress granules involved in the pathogenesis of Amyotrophic Lateral Sclerosis? None yes\n",
      "Does TGF-beta play a role in cardiac regeneration after myocardial infarction? no yes\n",
      "Is DITPA a thyroid hormone analog utilized in experimental and clinical studies no yes\n",
      "Is MammaPrint cleared by the United States Food and Drug Administration?  no yes\n",
      "Is amantadine effective for treatment of disorders conciousness? yes yes\n",
      "Is GAGA associated with nucleosome-free regions (NFR)? no yes\n",
      "Is amiodarone a class I anti-arrhythmic drug? yes no\n",
      "Is SLC22A3 expressed in the brain? yes yes\n"
     ]
    }
   ],
   "source": [
    "q = yesno[5]\n",
    "for q in yesno[:40]:\n",
    "    print q.question, q.exact_answer, q.exact_answer_ref\n",
    "#     for i in q.ranked_sentences():\n",
    "#         print i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/yesno_BioASQ-task6bPhaseB-testset5.json'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yesno_ans_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
