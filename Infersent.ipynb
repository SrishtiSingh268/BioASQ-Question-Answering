{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'nli/infersent/'\n",
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli/infersent\n"
     ]
    }
   ],
   "source": [
    "cd nli/infersent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "GLOVE_PATH = '/Volumes/Nitish-Passport/bioasq_files/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved_models/infersent.allnli.pickle'\n",
    "model = torch.load(model_path, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_glove_path(GLOVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'This is a sample sentence.',\n",
    "    'The cat likes to walk.',\n",
    "    'The cat likes to talk.',\n",
    "    'The dog likes to talk.',\n",
    "    'This is a completely unrelated sentence.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17(/17) words with glove vectors\n",
      "Vocab size : 17\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 31/36 (86.11 %)\n",
      "Speed : 7.6 sentences/s (cpu mode, bsize=2)\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(sentences, bsize=2, tokenize=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4096)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "def sim(sent1, sent2):\n",
    "    em = model.encode([sent1, sent2], tokenize=False, verbose=True)\n",
    "    return cosine(em[0], em[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'sentence',\n",
       " 'This',\n",
       " 'is',\n",
       " 'walk',\n",
       " 'dog',\n",
       " '.',\n",
       " 'sample',\n",
       " 'to',\n",
       " 'completely',\n",
       " 'unrelated',\n",
       " 'likes',\n",
       " 'The',\n",
       " 'cat',\n",
       " '</s>',\n",
       " 'talk',\n",
       " '<s>']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_word_dict(sentences).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "run data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "GLOVE_PATH = '/Volumes/Nitish-Passport/bioasq_files/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = [\n",
    "    'I do not want to go home.',\n",
    "    'He likes butter.',\n",
    "    'He never speaks loud.',\n",
    "    'The weather is good',\n",
    "    'What is the matter?',\n",
    "    'He never speaks loud.',\n",
    "    'He made two mistakes',\n",
    "]\n",
    "s2 = [\n",
    "    'I wish to go home.',\n",
    "    'He hates butter.',\n",
    "    'He never speaks soft.',\n",
    "    'The weather is bad',\n",
    "    'What is the matter with you?',\n",
    "    'He always speaks soft.',\n",
    "    'He made mistakes twice.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36(/36) words with glove vectors\n"
     ]
    }
   ],
   "source": [
    "word_dict = get_word_dict(s1 + s2)\n",
    "word_vec = get_glove(word_dict, GLOVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 0, 2, 0, 2, 0]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli_net = torch.load('saved_models/nlimodels/model.pickle', map_location='cpu')\n",
    "nli_net.eval()\n",
    "outputs = []\n",
    "for i in range(len(s1)):\n",
    "    ss1 = [['<s>'] + [word for word in word_tokenize(sent) if word in word_vec] +  ['</s>'] for sent in [s1[i]]]\n",
    "    ss2 = [['<s>'] + [word for word in word_tokenize(sent) if word in word_vec] +  ['</s>'] for sent in [s2[i]]]\n",
    "    # ss1 = sorted(ss1, key = lambda x: len(x), reverse=True)\n",
    "    # ss2 = sorted(ss2, key = lambda x: len(x), reverse=True)\n",
    "    s1_batch, s1_len = get_batch(ss1, word_vec)\n",
    "    s2_batch, s2_len = get_batch(ss2, word_vec)\n",
    "    s1_batch, s2_batch = Variable(s1_batch), Variable(s2_batch)\n",
    "    output = nli_net((s1_batch, s1_len), (s2_batch, s2_len))\n",
    "    outputs.append(output.data.max(1)[1].numpy()[0])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['I do not want to go home.',\n",
       "  'He likes butter.',\n",
       "  'He never speaks loud.',\n",
       "  'The weather is good',\n",
       "  'What is the matter?',\n",
       "  'He never speaks loud.',\n",
       "  'He made two mistakes'],\n",
       " ['I wish to go home.',\n",
       "  'He hates butter.',\n",
       "  'He never speaks soft.',\n",
       "  'The weather is bad',\n",
       "  'What is the matter with you?',\n",
       "  'He always speaks soft.',\n",
       "  'He made mistakes twice.'])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1, s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prostrcustus transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli/infersent/data\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/nli/infersent/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.load('matmul_glove_med.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, V = np.linalg.svd(mat, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 200), (200,), (200, 200))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape, s.shape, V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = U.dot(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('prostrcustus_transformation_matrix.npy', tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataLoader import DataLoader\n",
    "\n",
    "input_path = 'input/BioASQ-trainingDataset5b.json'\n",
    "# input_path = 'input/BioASQ-task6bPhaseB-testset3.json'\n",
    "data = DataLoader(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_vectors_file = '/Volumes/Nitish-Passport/bioasq_files/wikipedia-pubmed-and-PMC-w2v.bin'\n",
    "\n",
    "input_glove_file = '/Volumes/Nitish-Passport/bioasq_files/glove.840B.300d.txt'\n",
    "new_glove_file = '/Volumes/Nitish-Passport/bioasq_files/%s_glove.840B.300d.txt' % data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/nli/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run hypotheses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: /Users/nitish/.local/share/bllipparser/GENIA+PubMed\n",
      "Model directory already exists, not reinstalling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# RerankingParser._parser_model_loaded = False\n",
    "# rrp = RerankingParser.from_unified_model_dir('/Users/nitish/.local/share/bllipparser/GENIA+PubMed')\n",
    "# # fetch_and_load('GENIA+PubMed', verbose=True)\n",
    "# yesno = data.get_questions_of_type('yesno')\n",
    "# for q in tqdm(yesno):\n",
    "#     q.assertion_pos = q2s(q.question, rrp)\n",
    "set_assertions_for_yesno_questions(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesno = data.get_questions_of_type('yesno')\n",
    "all_sentences = []\n",
    "for q in yesno:\n",
    "    all_sentences.append(q.assertion_pos)\n",
    "    all_sentences += q.snippet_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli/infersent\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/nli/infersent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = get_word_dict(all_sentences)\n",
    "tokens = word_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run create_glove_embeddings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubtator_vectors = word2vec.load(pubmed_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "\n",
    "with open('/Users/nitish/acads/11797/bioasq/nli/infersent/data/uncommon_vocab.pkl', 'rb') as fp:\n",
    "    uncommon_vocab = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = np.load('prostrcustus_transformation_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli/infersent\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 5000 words\n",
      "Finished 10000 words\n",
      "Finished 15000 words\n",
      "Finished 20000 words\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "with open(new_glove_file, 'w') as fp:\n",
    "    for word in tokens:\n",
    "        k += 1\n",
    "        if k % 5000 == 0:\n",
    "            print('Finished %d words' % k)\n",
    "        if word in uncommon_vocab and word in pubtator_vectors:\n",
    "            vec = tm.dot(pubtator_vectors[word][:, np.newaxis])[:, 0]\n",
    "            line = ' '.join([word] + [str(i) for i in vec])\n",
    "            fp.write('%s\\n' % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec = tm.dot(pubtator_vectors['localizes'][:, np.newaxis])[:, 0].shape\n",
    "# vec.lot_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run infersent on yesno questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run dataLoader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'input/BioASQ-trainingDataset5b.json'\n",
    "# input_path = 'input/BioASQ-trainingDataset6b.json'\n",
    "# input_path = 'input/BioASQ-task6bPhaseB-testset3.json'\n",
    "data = DataLoader(input_path)\n",
    "\n",
    "input_glove_file = '/Volumes/Nitish-Passport/bioasq_files/glove.840B.300d.txt'\n",
    "new_glove_file = '/Volumes/Nitish-Passport/bioasq_files/%s_glove.840B.300d.txt' % data.name\n",
    "yesno_ans_file = 'output/yesno_%s.json' % data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/nli/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run hypotheses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: /Users/nitish/.local/share/bllipparser/GENIA+PubMed\n",
      "Model directory already exists, not reinstalling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:03<00:00,  7.82it/s]\n"
     ]
    }
   ],
   "source": [
    "set_assertions_for_yesno_questions(data)\n",
    "\n",
    "yesno = data.get_questions_of_type('yesno')\n",
    "all_sentences = []\n",
    "for q in yesno:\n",
    "    all_sentences.append(q.assertion_pos)\n",
    "    all_sentences += q.snippet_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli/infersent\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/nli/infersent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19213(/20022) words with glove vectors\n"
     ]
    }
   ],
   "source": [
    "word_dict = get_word_dict(all_sentences)\n",
    "word_vec = get_glove(word_dict, input_glove_file, new_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yesno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8 0 yes\n",
      "3 3 yes\n",
      "11 1 yes\n",
      "0 0 No\n",
      "0 12 yes\n"
     ]
    }
   ],
   "source": [
    "nli_net = torch.load('saved_models/nlimodels/model.pickle', map_location='cpu')\n",
    "nli_net.eval()\n",
    "\n",
    "for q in yesno[:5]:\n",
    "    outputs = []\n",
    "    sentences = [i['text'] for i in q.ranked_sentences()[:20]]\n",
    "    s1, s2 = sentences, [q.assertion_pos] * len(sentences)\n",
    "#     s2, s1 = sentences, [q.assertion_pos] * len(sentences)\n",
    "#     if q.exact_answer_ref == 'yes':\n",
    "#         continue\n",
    "    total = 0\n",
    "    for i in range(len(s1)):\n",
    "        ss1 = [['<s>'] + [word for word in word_tokenize(sent) if word in word_vec] +  ['</s>'] for sent in [s1[i]]]\n",
    "        ss2 = [['<s>'] + [word for word in word_tokenize(sent) if word in word_vec] +  ['</s>'] for sent in [s2[i]]]\n",
    "        # ss1 = sorted(ss1, key = lambda x: len(x), reverse=True)\n",
    "        # ss2 = sorted(ss2, key = lambda x: len(x), reverse=True)\n",
    "        s1_batch, s1_len = get_batch(ss1, word_vec)\n",
    "        s2_batch, s2_len = get_batch(ss2, word_vec)\n",
    "        s1_batch, s2_batch = Variable(s1_batch), Variable(s2_batch)\n",
    "        output = nli_net((s1_batch, s1_len), (s2_batch, s2_len))\n",
    "        total += output\n",
    "        outputs.append(output.data.max(1)[1].numpy()[0])\n",
    "    print (np.array(outputs) == 0).sum(), (np.array(outputs) == 2).sum(), q.exact_answer_ref #, total.data.max(1)[1].numpy()[0] if total != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.5178 -0.6057 -0.9143\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [2:36:06<00:00, 20.81s/it]  \n"
     ]
    }
   ],
   "source": [
    "nli_net = torch.load('saved_models/nlimodels/model.pickle', map_location='cpu')\n",
    "nli_net.eval()\n",
    "\n",
    "def get_answer(n_entail, n_contradict):\n",
    "    if n_entail > n_contradict:\n",
    "        return 'yes'\n",
    "    elif n_contradict > n_entail:\n",
    "        return 'no'\n",
    "    else:\n",
    "        if n_entail == 0:\n",
    "            return 'no'\n",
    "        else:\n",
    "            return 'yes'\n",
    "\n",
    "# entailments = []\n",
    "# answers = []\n",
    "for q in tqdm(yesno[50:]):\n",
    "    outputs = []\n",
    "    sentences = [i['text'] for i in q.ranked_sentences()]\n",
    "    s1, s2 = sentences, [q.assertion_pos] * len(sentences)\n",
    "    total = 0\n",
    "    for i in range(len(s1)):\n",
    "        ss1 = [['<s>'] + [word for word in word_tokenize(sent) if word in word_vec] +  ['</s>'] for sent in [s1[i]]]\n",
    "        ss2 = [['<s>'] + [word for word in word_tokenize(sent) if word in word_vec] +  ['</s>'] for sent in [s2[i]]]\n",
    "        s1_batch, s1_len = get_batch(ss1, word_vec)\n",
    "        s2_batch, s2_len = get_batch(ss2, word_vec)\n",
    "        s1_batch, s2_batch = Variable(s1_batch), Variable(s2_batch)\n",
    "        output = nli_net((s1_batch, s1_len), (s2_batch, s2_len))\n",
    "        total += output\n",
    "        outputs.append(output.data.max(1)[1].numpy()[0])\n",
    "    n_entail = (np.array(outputs) == 0).sum()\n",
    "    n_contradict = (np.array(outputs) == 2).sum()\n",
    "    total_res = total.data.max(1)[1].numpy()[0] if isinstance(total, Variable) else 0\n",
    "    q.exact_answer = get_answer(n_entail, n_contradict)\n",
    "    answers.append((n_entail, n_contradict, q.exact_answer_ref, q.exact_answer))\n",
    "#     entailments.append((n_entail, n_contradict, total_res, q.exact_answer))\n",
    "\n",
    "# data.eval_yesno()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy = 0.568273 (283 / 498)\n",
      "YES Accuracy = 0.565611 (250 / 442)\n",
      "No Accuracy = 0.589286 (33 / 56)\n"
     ]
    }
   ],
   "source": [
    "def get_answer(n_entail, n_contradict):\n",
    "    if n_entail > n_contradict:\n",
    "        return 'yes'\n",
    "    elif n_contradict > n_entail:\n",
    "        return 'no'\n",
    "    else:\n",
    "        if n_entail == 0:\n",
    "            return 'no'\n",
    "        else:\n",
    "            return 'yes'\n",
    "\n",
    "def eval_yesno(questions):\n",
    "    yes_correct = 0.0\n",
    "    no_correct = 0.0\n",
    "    total_yes = 0.0\n",
    "    total_no = 0.0\n",
    "\n",
    "    for q in questions:\n",
    "        if not q.exact_answer_ref or not q.exact_answer:\n",
    "            continue\n",
    "        q.exact_answer_ref = q.exact_answer_ref.lower()\n",
    "        if q.exact_answer_ref == 'yes':\n",
    "            total_yes += 1\n",
    "            yes_correct += (q.exact_answer_ref == q.exact_answer)\n",
    "        if q.exact_answer_ref == 'no':\n",
    "            total_no += 1\n",
    "            no_correct += (q.exact_answer_ref == q.exact_answer)\n",
    "\n",
    "    total_correct = yes_correct + no_correct\n",
    "    total_q = total_yes + total_no\n",
    "    total_acc = total_correct / total_q if total_q > 0 else 0\n",
    "    yes_acc = yes_correct / total_yes if total_yes > 0 else 0\n",
    "    no_acc = no_correct / total_no if total_no > 0 else 0\n",
    "    print('Total Accuracy = %2f (%d / %d)' % (total_acc, total_correct, total_q))\n",
    "    print('YES Accuracy = %2f (%d / %d)' % (yes_acc, yes_correct, total_yes))\n",
    "    print('No Accuracy = %2f (%d / %d)' % (no_acc, no_correct, total_no))\n",
    "\n",
    "for itr, q in enumerate(yesno):\n",
    "    q.exact_answer = get_answer(answers[itr][0], answers[itr][1])\n",
    "\n",
    "eval_yesno(yesno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 0, u'yes', 'yes'),\n",
       " (3, 3, u'yes', 'yes'),\n",
       " (11, 1, u'yes', 'yes'),\n",
       " (0, 0, u'no', 'no'),\n",
       " (0, 13, u'yes', 'no'),\n",
       " (0, 55, u'yes', 'no'),\n",
       " (20, 0, u'yes', 'yes'),\n",
       " (4, 2, u'yes', 'yes'),\n",
       " (0, 0, u'Yes', 'no'),\n",
       " (21, 5, u'yes', 'yes'),\n",
       " (2, 11, u'yes', 'no'),\n",
       " (19, 1, u'yes', 'yes'),\n",
       " (7, 0, u'yes', 'yes'),\n",
       " (3, 1, u'yes', 'yes'),\n",
       " (4, 0, u'yes', 'yes')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.save_yesno_answers(yesno_ans_file)\n",
    "# data.load_answers_from_file(yesno_ans_file, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there an association between Klinefelter syndrome and breast cancer?\n",
      "yes\n",
      "Male breast cancer risk factors show strong association with BRCA2 mutations, as well as Klinefelter syndrome\n",
      "Screening for breast cancer in male-to-female transsexuals should be undertaken for those with additional risk factors (e.g., family history, BRCA2 mutation, Klinefelter syndrome) and should be available to those who desire screening, preferably in a clinical trial\n",
      "Patients with 47, XXY karyotype (Klinefelter syndrome) appear to have increased risk of developing cancer, especially male breast cancer, germ cell tumours and non Hodgkin lymphomas, but rarely acute myeloid leukaemia\n",
      "Major risk factors for developing male BC include clinical disorders involving hormonal imbalances (excess of estrogen or a deficiency of testosterone as seen in patients with Klinefelter syndrome) and a positive family history for breast cancer\n",
      "The main risk factors include: the mutation of genes BRCA 1 and 2, Klinefelter's syndrome, alcohol, liver disease, obesity\n",
      "Klinefelter syndrome (OR = 24.7; 95% CI = 8.94 to 68.4) and gynecomastia (OR = 9.78; 95% CI = 7.52 to 12.7) were also statistically significantly associated with risk, relations that were independent of BMI\n",
      "Although aetiology is still unclear, constitutional, environmental, hormonal (abnormalities in estrogen/androgen balance) and genetic (positive family history, Klinefelter syndrome, mutations in BRCA1 and specially BRCA2) risk factors are already known\n",
      "The largest study found 19.2- and 57.8-fold increases in incidence and mortality, respectively, with particularly high risks among 47,XXY mosaics\n",
      "CONCLUSIONS: Additional well-designed epidemiologic studies are needed to clarify which patients with KS are at a high risk of developing MBC and to distinguish between possible predisposing factors, including altered endogenous hormones\n"
     ]
    }
   ],
   "source": [
    "q = yesno[5]\n",
    "print q.question\n",
    "print q.exact_answer\n",
    "for i in q.ranked_sentences():\n",
    "    print i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
