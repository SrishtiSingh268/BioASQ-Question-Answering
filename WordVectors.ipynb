{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli/infersent/data\n"
     ]
    }
   ],
   "source": [
    "cd nli/infersent/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import word2vec\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "path = '/Volumes/Nitish-Passport/bioasq_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.load(path + 'wikipedia-pubmed-and-PMC-w2v.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5443656, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'</s>', u'the', u',', u'.', u'of', u'and', u'in', u'to', u')', u'('],\n",
       "      dtype='<U78')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11046166, -0.05040035,  0.03913487, -0.10067561,  0.00037703,\n",
       "        0.02872419, -0.11152618,  0.02517193,  0.06513785,  0.02294562,\n",
       "        0.10788579, -0.04768647,  0.08999117, -0.00468054, -0.02473051,\n",
       "        0.02291509, -0.04805623,  0.00559252,  0.0976434 , -0.06541612,\n",
       "        0.05561662,  0.04049605, -0.04545286,  0.09474371, -0.1204014 ,\n",
       "       -0.08219351, -0.01654021,  0.01995185,  0.14260587,  0.00395526,\n",
       "       -0.02792581,  0.1262137 , -0.05358404, -0.00615384,  0.05340649,\n",
       "        0.00637606,  0.04131497, -0.01639221,  0.02490863, -0.02895821,\n",
       "       -0.00611441, -0.04656184,  0.01158576, -0.02189317, -0.00383917,\n",
       "        0.06553224, -0.1481678 , -0.04172103,  0.07355045,  0.07336105,\n",
       "        0.05634607, -0.03150396,  0.12683521, -0.05354187, -0.07325022,\n",
       "       -0.03542487,  0.037143  , -0.01277449,  0.00539332,  0.10931038,\n",
       "        0.03713041,  0.07804288, -0.0237392 ,  0.04356174,  0.10646453,\n",
       "        0.02710467,  0.00647589, -0.02109452,  0.07590852,  0.02625624,\n",
       "       -0.16814028,  0.00203134,  0.09141079,  0.07475183, -0.08541793,\n",
       "        0.06611883,  0.04173591,  0.08343008,  0.07576196, -0.17573607,\n",
       "       -0.02004314,  0.03422621, -0.0329514 ,  0.08065788,  0.0259792 ,\n",
       "       -0.02248269,  0.01981783, -0.06007839,  0.01626796,  0.05024398,\n",
       "        0.04094274, -0.04337232,  0.05549246, -0.03873668,  0.06820657,\n",
       "       -0.0089989 , -0.0749075 , -0.01840459,  0.05348794, -0.02241084,\n",
       "        0.09366105, -0.05718687, -0.01562454,  0.03136991,  0.01328264,\n",
       "        0.04220108,  0.06552505,  0.04252696,  0.04662199, -0.11297148,\n",
       "        0.06389298,  0.09851643, -0.10990842, -0.099302  , -0.08839995,\n",
       "       -0.18497466, -0.02464989,  0.00892334, -0.0106686 ,  0.0709679 ,\n",
       "       -0.05563895, -0.14322262, -0.14573777, -0.04716303, -0.03945352,\n",
       "        0.06512258, -0.00521486, -0.02146114,  0.06094313,  0.04738534,\n",
       "       -0.08772602, -0.06288661, -0.01444598,  0.15427695, -0.03754129,\n",
       "       -0.0017387 , -0.09350052, -0.03747255, -0.02144549, -0.02458374,\n",
       "       -0.09884005, -0.04586565,  0.0411166 ,  0.10189304,  0.00703789,\n",
       "       -0.0727575 , -0.00602503, -0.13719606,  0.03075726, -0.1264946 ,\n",
       "        0.0838249 , -0.07641238,  0.03661942, -0.04605367, -0.02244932,\n",
       "        0.06924362, -0.1371461 ,  0.01563485,  0.06637673, -0.02723642,\n",
       "        0.07649442,  0.04596143, -0.02260369, -0.01921298, -0.06342388,\n",
       "        0.02285   ,  0.04121691,  0.02801937,  0.05658125,  0.01574342,\n",
       "        0.01102745,  0.21150108, -0.11845541,  0.02065455,  0.05854769,\n",
       "       -0.01883318,  0.01086872,  0.03723367,  0.0175297 ,  0.0045114 ,\n",
       "       -0.04575202,  0.10217067, -0.10288481, -0.03209937,  0.06715483,\n",
       "        0.01076325,  0.11870413, -0.02436936,  0.13630584, -0.09376761,\n",
       "        0.14252773,  0.15846439,  0.00971729,  0.12150919,  0.05258713,\n",
       "       -0.12801304,  0.06064231, -0.03140734,  0.04086035,  0.00450846])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_vector('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('wiki_pubmed_vocab.pkl', 'wb') as fp:\n",
    "#     pickle.dump(model.vocab, fp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "with open(path + 'glove.840B.300d.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        vocab.append(line.split(' ', 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('glove_vocab.pkl', 'wb') as fp:\n",
    "#     pickle.dump(vocab, fp)\n",
    "    pickle.dump(vocab, fp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove_vocab.pkl', 'rb') as fp:\n",
    "    glove_vocab = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wiki_pubmed_vocab.pkl', 'rb') as fp:\n",
    "    pubmed_vocab = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pubmed_vocab = model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_vocab = []\n",
    "\n",
    "for word in pubmed_vocab[:1000]:\n",
    "    if word in glove_vocab:\n",
    "        common_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vocab = set(glove_vocab)\n",
    "pubmed_vocab = set(pubmed_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_vocab = pubmed_vocab.intersection(glove_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('common_vocab.pkl', 'wb') as fp:\n",
    "#     pickle.dump(common_vocab, fp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1102654, 5443651, 2196016)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_vocab), len(pubmed_vocab), len(glove_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('common_vocab.pkl', 'rb') as fp:\n",
    "    common_vocab = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_vocab = np.array(list(common_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Feijo', 'Inculcation', 'Alys', ..., 'p21Cip1', '11874', 'Lancieux'],\n",
       "      dtype='|S78')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([model[word] for word in common_vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1102654, 200)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pubmed_vectors_train.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 words\n",
      "Loaded 200000 words\n",
      "Loaded 300000 words\n",
      "Loaded 400000 words\n",
      "Loaded 500000 words\n",
      "Loaded 600000 words\n",
      "Loaded 700000 words\n",
      "Loaded 800000 words\n",
      "Loaded 900000 words\n",
      "Loaded 1000000 words\n",
      "Loaded 1100000 words\n",
      "Loaded 1200000 words\n",
      "Loaded 1300000 words\n",
      "Loaded 1400000 words\n",
      "Loaded 1500000 words\n",
      "Loaded 1600000 words\n",
      "Loaded 1700000 words\n",
      "Loaded 1800000 words\n",
      "Loaded 1900000 words\n",
      "Loaded 2000000 words\n",
      "Loaded 2100000 words\n",
      "Found 2196016 words with glove vectors\n"
     ]
    }
   ],
   "source": [
    "glove_word_vec = {}\n",
    "glove_path = path + 'glove.840B.300d.txt'\n",
    "with open(glove_path, 'r') as f:\n",
    "    itr = 0\n",
    "    for line in f:\n",
    "        itr += 1\n",
    "        word, vec = line.split(' ', 1)\n",
    "        glove_word_vec[word] = np.array(list(map(float, vec.split())))\n",
    "        if itr % 100000 == 0:\n",
    "            print('Loaded {0} words'.format(itr))\n",
    "print('Found {0} words with glove vectors'.format(len(glove_word_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 vectors\n",
      "Loaded 100000 vectors\n",
      "Loaded 200000 vectors\n",
      "Loaded 300000 vectors\n",
      "Loaded 400000 vectors\n",
      "Loaded 500000 vectors\n",
      "Loaded 600000 vectors\n",
      "Loaded 700000 vectors\n",
      "Loaded 800000 vectors\n",
      "Loaded 900000 vectors\n",
      "Loaded 1000000 vectors\n",
      "Loaded 1100000 vectors\n",
      "Loaded 1102653 vectors\n"
     ]
    }
   ],
   "source": [
    "N = len(common_vocab)\n",
    "M = len(glove_word_vec[common_vocab[0]])\n",
    "Y = np.zeros((N, M))\n",
    "for itr, word in enumerate(common_vocab):\n",
    "    Y[itr] = glove_word_vec[word]\n",
    "    if itr % 100000 == 0:\n",
    "        print('Loaded {0} vectors'.format(itr))\n",
    "print('Loaded {0} vectors'.format(itr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('glove_vectors_train.npy', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected list, got numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-148b0b0c5556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.to_object_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected list, got numpy.ndarray"
     ]
    }
   ],
   "source": [
    "l = [[1, 5.6, 7], [3, 5, 9]]\n",
    "pd.lib.to_object_array(Y[:10]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  5.6,  7. ],\n",
       "       [ 3. ,  5. ,  9. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(Y[:1000]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10000\n",
    "B = np.zeros((k, len(Y[0])))\n",
    "# np.copyto(A, Y[:k])\n",
    "B[:k] = Y[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('pubmed_vectors_train.npy')\n",
    "Y = np.load('glove_vectors_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X[:1000, :]\n",
    "Y_sample = Y[:1000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1102654, 200), (1102654, 300), (1000, 200), (1000, 300))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape, X_sample.shape, Y_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sample_glove_vectors_train.npy', Y_sample)\n",
    "np.save('sample_pubmed_vectors_train.npy', X_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PubMed Uncommon Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('common_vocab.pkl', 'rb') as fp:\n",
    "    common_vocab = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncommon_vocab = [word for word in model.vocab if word not in common_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4341000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncommon_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('uncommon_vocab.pkl', 'wb') as fp:\n",
    "#     pickle.dump(uncommon_vocab, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('uncommon_vocab.pkl', 'rb') as fp:\n",
    "    uncommon_vocab = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncommon_vocab = set(uncommon_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4340997"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncommon_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([model[word] for word in uncommon_vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "np.save(path + 'pubmed_vectors_test.npy', X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/11797/bioasq/nli/infersent/data\n"
     ]
    }
   ],
   "source": [
    "cd ~/acads/11797/bioasq/nli/infersent/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tm = np.load('prostrcustus_transformation_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 200)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('glove_vectors_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.load('pubmed_vectors_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1102654, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1102654, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X[:10, :]\n",
    "y = Y[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1102654, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = Y.dot(tm.T)\n",
    "transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = y.dot(tm.T)\n",
    "np.linalg.norm(X - transformed, axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
